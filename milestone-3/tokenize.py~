import re

s = '''Oh, U.S.A no,\" she\'s saying, \"our 400blender can\'t handle something this hard! harshitagarwal37@gmail.com https://stackoverflow.com/questions!!!!(hello) nice.'''

def tokenize_(s):
    pattern = r'''\d+|(`\-=~!@#$%^&*()_+\[\]{};\'\\:"|<,./<>?)+|[A-Z][A-Z]+|http[s]?://[\w\./]+|[\w]+@[\w]+\.[\w]+|[a-z][a-z]+|[\w\.]+|[\w]+|[-'a-z]+|[\S]+''' 

    l = re.findall(pattern, s) 	
    return l

print tokenize_(s)
